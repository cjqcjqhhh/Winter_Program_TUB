{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks using PyTorch framework\n",
    "---\n",
    "![](resources/torch.png)\n",
    "## Comparing performance of classical networks to convolutional neural networks \n",
    "\n",
    "## Typical Deep Learning workflow:\n",
    "\n",
    "1. Load your training datasets, and(if needed) convert them into PyTorch datasets\n",
    "2. Build PyTorch-DataLoaders using your datasets, set shuffle = True and define batch size\n",
    "3. Define the neural network structure\n",
    "4. Training process:\n",
    "    - Define optimizer\n",
    "    - Define loss function\n",
    "    - Define # of training iterations\n",
    "    - Train your model\n",
    "5. Evaluation process:\n",
    "    - Use your model to predict labels for your test set\n",
    "    - evaluate accuracy with true labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Pair programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "training_data = torchvision.datasets.MNIST('data/', train=True, download=True, transform=transform)\n",
    "testing_data = torchvision.datasets.MNIST('data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = CustomDataset(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomDataset():\n",
    "\n",
    "    def __init__(self, data, labels):\n",
    "\n",
    "        self.data = torch.Tensordata\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        landmarks = np.array([landmarks])\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return datapoint, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data more closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_point = training_data.data[0]\n",
    "test_target = training_data.targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data sample: (28, 28)\n",
      "First row of data sample: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of data sample: {np.array(test_data_point).shape}')\n",
    "print(f'First row of data sample: {np.array(test_data_point)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.imshow(test_data_point)\n",
    "plt.show()\n",
    "\n",
    "print(f'Label: {test_target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders to feed data into our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testing_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.linear_layer1 = torch.nn.Linear(self.input_dim, 100)\n",
    "        self.linear_layer2 = torch.nn.Linear(100, 50)\n",
    "        self.linear_layer3 = torch.nn.Linear(50, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Layer 1 + activation\n",
    "        x = self.linear_layer1(x.view(-1, self.input_dim))\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        # Layer 2 + activation\n",
    "        x = self.linear_layer2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        # Layer 3 + activation\n",
    "        x = self.linear_layer3(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an object of the neural network\n",
    "# Optimizer\n",
    "# Define a Loss Function\n",
    "# Run the training loop\n",
    "\n",
    "neural_net = NeuralNet(784, 10)\n",
    "optimizer = torch.optim.SGD(params=neural_net.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda\\lib\\site-packages\\torch\\nn\\functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.3022429451942443\n",
      "Epoch: 0, loss: 2.3007626662254332\n",
      "Epoch: 0, loss: 2.299957752227783\n",
      "Loss after epoch: 0 = 2.299291226196289\n",
      "Epoch: 1, loss: 2.2946997702121736\n",
      "Epoch: 1, loss: 2.293743654131889\n",
      "Epoch: 1, loss: 2.2925852898756665\n",
      "Loss after epoch: 1 = 2.2913902076721193\n",
      "Epoch: 2, loss: 2.282484582901001\n",
      "Epoch: 2, loss: 2.2793360310792923\n",
      "Epoch: 2, loss: 2.274843676249186\n",
      "Loss after epoch: 2 = 2.2706192380905152\n",
      "Epoch: 3, loss: 2.23801264667511\n",
      "Epoch: 3, loss: 2.226839868307114\n",
      "Epoch: 3, loss: 2.2125319498380027\n",
      "Loss after epoch: 3 = 2.200229097811381\n",
      "Epoch: 4, loss: 2.118838673591614\n",
      "Epoch: 4, loss: 2.0975600358247757\n",
      "Epoch: 4, loss: 2.078076052904129\n",
      "Loss after epoch: 4 = 2.0646990529378257\n",
      "Epoch: 5, loss: 1.9822263782024383\n",
      "Epoch: 5, loss: 1.9683685910105706\n",
      "Epoch: 5, loss: 1.955557133158048\n",
      "Loss after epoch: 5 = 1.9464758664449056\n",
      "Epoch: 6, loss: 1.8920758652687073\n",
      "Epoch: 6, loss: 1.8842118031978607\n",
      "Epoch: 6, loss: 1.8758384487231572\n",
      "Loss after epoch: 6 = 1.8702470897038779\n",
      "Epoch: 7, loss: 1.8379350847005844\n",
      "Epoch: 7, loss: 1.831379900455475\n",
      "Epoch: 7, loss: 1.8256101736625037\n",
      "Loss after epoch: 7 = 1.8219951267242431\n",
      "Epoch: 8, loss: 1.799382466197014\n",
      "Epoch: 8, loss: 1.795929443359375\n",
      "Epoch: 8, loss: 1.7929573008616766\n",
      "Loss after epoch: 8 = 1.7900646472295125\n",
      "Epoch: 9, loss: 1.7747650773525239\n",
      "Epoch: 9, loss: 1.7709756562709809\n",
      "Epoch: 9, loss: 1.7679024633169174\n",
      "Loss after epoch: 9 = 1.7656428773562114\n"
     ]
    }
   ],
   "source": [
    "# training loop:\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader, 1):\n",
    "        \n",
    "        # set optimizer gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        predictions = neural_net.forward(x)\n",
    "        \n",
    "        # backward pass + optimization step\n",
    "        loss = loss_fn(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch}, loss: {running_loss / i}')\n",
    "        \n",
    "    print(f'Loss after epoch: {epoch} = {running_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = neural_net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare regular Multilayer-perceptron performance against Convolutional neural network\n",
    "\n",
    "### How to compute output size after convolutional layer ??:\n",
    "- If you just set the channel input size, channel output size, kernel size for your Conv2D function -> output width = input_width - kernel_width + 1\n",
    "- Same for output height\n",
    "\n",
    "### How to compute output size after pooling layer ??:\n",
    "- If you just set the kernel size of your pooling layer, without inputing any other arguments -> output width = input_width / kernel_width\n",
    "- Same for output height\n",
    "\n",
    "#### If you change other input arguments to the Conv/MaxPool functions, the output sizes will be computed as explained in the docs:\n",
    "https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d\n",
    "\n",
    "- Nice visualizations of different kernel/filter/convolution strategies: https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Input(batch_size, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        # Input(batch_size, 6, 24, 24)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Input(batch_size, 16, 12, 12)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        # Input(batch_size, 16, 8, 8)\n",
    "        x = self.pool()\n",
    "        \n",
    "        # Input(batch_size, 16, 4, 4)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an object of the neural network\n",
    "# Optimizer\n",
    "# Define a Loss Function\n",
    "# Run the training loop\n",
    "\n",
    "neural_net = ConvNet()\n",
    "optimizer = torch.optim.SGD(params=neural_net.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop:\n",
    "for epoch in range(10):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader, 1):\n",
    "        \n",
    "        # set optimizer gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        predictions = neural_net.forward(x)\n",
    "        \n",
    "        # backward pass + optimization step\n",
    "        loss = loss_fn(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch}, loss: {running_loss / i}')\n",
    "        \n",
    "    print(f'\\nLoss after epoch: {epoch} = {running_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = neural_net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Build your own Neural Network classifiers:\n",
    "\n",
    "### Todos:\n",
    "1. Load the CIFAR 10 train and test dataset from the torchvision library that we have used above for the MNIST data:\n",
    "Documentation: https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "2. Create DataLoaders for the training and test size:\n",
    "    - experiment with different batch sizes\n",
    "3. Create one fully connected model and another Convolutional Neural Network, for each experiment with different layer sizes(# of neurons) and layer types:\n",
    "    - Conv layers preprocess the data\n",
    "    - Pooling layers preprocess the data\n",
    "    - Fully connected layer need to be added at the end to classify the data\n",
    "\n",
    "## Note: In this solution I only used 1 fully-connected(torch.nn.Linear) layer since it accelarates the training process significantly\n",
    "\n",
    "4. Evaluate the prediction accuracy(all correct classified points / number of points) of your Fully-connected and Convolutional Neural Networks\n",
    "\n",
    "5. Evaluate prediction accuracy of each class, e.g.: Correctly classified: 60% of planes, 70% of cars, 30% of housed etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 169467904/170498071 [00:11<00:00, 16541592.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "training_data = torchvision.datasets.CIFAR10('data/', train=True, download=True, transform=transform)\n",
    "testing_data = torchvision.datasets.CIFAR10('data/', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testing_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetCifar10(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNetCifar10, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(16 * 5 * 5, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Input(batch_size, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        # Input(batch_size, 6, 24, 24)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Input(batch_size, 16, 12, 12)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        # Input(batch_size, 16, 8, 8)\n",
    "        x = self.pool(x)\n",
    "                \n",
    "        # Input(batch_size, 16, 4, 4)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an object of the neural network\n",
    "# Optimizer\n",
    "# Define a Loss Function\n",
    "# Run the training loop\n",
    "\n",
    "neural_net = ConvNetCifar10()\n",
    "optimizer = torch.optim.SGD(params=neural_net.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.008464808821678\n",
      "Epoch: 0, loss: 1.8425456362366677\n",
      "Epoch: 0, loss: 1.7432613690098127\n",
      "\n",
      "Loss after epoch: 0 = 1.7341665418815613\n",
      "Epoch: 1, loss: 1.472133158683777\n",
      "Epoch: 1, loss: 1.4439459372758865\n",
      "Epoch: 1, loss: 1.4211917668183645\n",
      "\n",
      "Loss after epoch: 1 = 1.4177743427276612\n",
      "Epoch: 2, loss: 1.3192310163378715\n",
      "Epoch: 2, loss: 1.3122816373705863\n",
      "Epoch: 2, loss: 1.301391716102759\n",
      "\n",
      "Loss after epoch: 2 = 1.297793385734558\n",
      "Epoch: 3, loss: 1.236536273777485\n",
      "Epoch: 3, loss: 1.2335844233632087\n",
      "Epoch: 3, loss: 1.231391068160534\n",
      "\n",
      "Loss after epoch: 3 = 1.2304240695762634\n",
      "Epoch: 4, loss: 1.1988790969252587\n",
      "Epoch: 4, loss: 1.1896469817608595\n",
      "Epoch: 4, loss: 1.1822293835083644\n",
      "\n",
      "Loss after epoch: 4 = 1.1800174136543273\n",
      "Epoch: 5, loss: 1.1536464096307755\n",
      "Epoch: 5, loss: 1.1492350935935973\n",
      "Epoch: 5, loss: 1.143739526460568\n",
      "\n",
      "Loss after epoch: 5 = 1.1428605481052398\n",
      "Epoch: 6, loss: 1.1082255973815918\n",
      "Epoch: 6, loss: 1.109588011711836\n",
      "Epoch: 6, loss: 1.1132366749445597\n",
      "\n",
      "Loss after epoch: 6 = 1.1124529468917848\n",
      "Epoch: 7, loss: 1.0768548887073994\n",
      "Epoch: 7, loss: 1.0807977945953609\n",
      "Epoch: 7, loss: 1.086460542033116\n",
      "\n",
      "Loss after epoch: 7 = 1.0872411665439605\n",
      "Epoch: 8, loss: 1.0532898060977458\n",
      "Epoch: 8, loss: 1.0637283088713885\n",
      "Epoch: 8, loss: 1.0649918649991352\n",
      "\n",
      "Loss after epoch: 8 = 1.0648410530281067\n",
      "Epoch: 9, loss: 1.0413699473142624\n",
      "Epoch: 9, loss: 1.0458770063966514\n",
      "Epoch: 9, loss: 1.0484886750082174\n",
      "\n",
      "Loss after epoch: 9 = 1.0482750215435028\n"
     ]
    }
   ],
   "source": [
    "# training loop:\n",
    "for epoch in range(10):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader, 1):\n",
    "        \n",
    "        # set optimizer gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        predictions = neural_net.forward(x)\n",
    "        \n",
    "        # backward pass + optimization step\n",
    "        loss = loss_fn(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch}, loss: {running_loss / i}')\n",
    "        \n",
    "    print(f'\\nLoss after epoch: {epoch} = {running_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 62 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for (x, y) in test_loader:\n",
    "        \n",
    "        predictions = neural_net(x)\n",
    "        \n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        \n",
    "        total += y.size(0)\n",
    "        \n",
    "        correct += (predicted == y).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 56 %\n",
      "Accuracy of   car : 72 %\n",
      "Accuracy of  bird : 46 %\n",
      "Accuracy of   cat : 36 %\n",
      "Accuracy of  deer : 54 %\n",
      "Accuracy of   dog : 58 %\n",
      "Accuracy of  frog : 78 %\n",
      "Accuracy of horse : 72 %\n",
      "Accuracy of  ship : 81 %\n",
      "Accuracy of truck : 71 %\n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for (x, y) in test_loader:\n",
    "        \n",
    "        predictions = neural_net(x)\n",
    "        \n",
    "        _, predicted = torch.max(predictions, 1)\n",
    "        \n",
    "        c = (predicted == y).squeeze()\n",
    "        \n",
    "        for i in range(4):\n",
    "            label = y[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
