{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks using PyTorch framework\n",
    "---\n",
    "![](resources/torch.png)\n",
    "## Comparing performance of classical networks to convolutional neural networks \n",
    "\n",
    "## Typical Deep Learning workflow:\n",
    "\n",
    "1. Load your training datasets, and(if needed) convert them into PyTorch datasets\n",
    "2. Build PyTorch-DataLoaders using your datasets, set shuffle = True and define batch size\n",
    "3. Define the neural network structure\n",
    "4. Training process:\n",
    "    - Define optimizer\n",
    "    - Define loss function\n",
    "    - Define # of training iterations\n",
    "    - Train your model\n",
    "5. Evaluation process:\n",
    "    - Use your model to predict labels for your test set\n",
    "    - evaluate accuracy with true labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Pair programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "training_data = torchvision.datasets.MNIST('data/', train=True, download=True, transform=transform)\n",
    "testing_data = torchvision.datasets.MNIST('data/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data more closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_point = training_data.data[0]\n",
    "test_target = training_data.targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of data sample: {np.array(test_data_point).shape}')\n",
    "print(f'First row of data sample: {np.array(test_data_point)[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.imshow(test_data_point)\n",
    "plt.show()\n",
    "\n",
    "print(f'Label: {test_target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloaders to feed data into our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testing_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.linear_layer1 = torch.nn.Linear(self.input_dim, 100)\n",
    "        self.linear_layer2 = torch.nn.Linear(100, 50)\n",
    "        self.linear_layer3 = torch.nn.Linear(50, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Layer 1 + activation\n",
    "        x = self.linear_layer1(x.view(-1, self.input_dim))\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        # Layer 2 + activation\n",
    "        x = self.linear_layer2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        # Layer 3 + activation\n",
    "        x = self.linear_layer3(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an object of the neural network\n",
    "# Optimizer\n",
    "# Define a Loss Function\n",
    "# Run the training loop\n",
    "\n",
    "neural_net = NeuralNet(784, 10)\n",
    "optimizer = torch.optim.SGD(params=neural_net.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training loop:\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader, 1):\n",
    "        \n",
    "        # set optimizer gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        predictions = neural_net.forward(x)\n",
    "        \n",
    "        # backward pass + optimization step\n",
    "        loss = loss_fn(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch}, loss: {running_loss / i}')\n",
    "        \n",
    "    print(f'Loss after epoch: {epoch} = {running_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = neural_net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare regular Multilayer-perceptron performance against Convolutional neural network\n",
    "\n",
    "### How to compute output size after convolutional layer ??:\n",
    "- If you just set the channel input size, channel output size, kernel size for your Conv2D function -> output width = input_width - kernel_width + 1\n",
    "- Same for output height\n",
    "\n",
    "### How to compute output size after pooling layer ??:\n",
    "- If you just set the kernel size of your pooling layer, without inputing any other arguments -> output width = input_width / kernel_width\n",
    "- Same for output height\n",
    "\n",
    "#### If you change other input arguments to the Conv/MaxPool functions, the output sizes will be computed as explained in the docs:\n",
    "https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d\n",
    "\n",
    "- Nice visualizations of different kernel/filter/convolution strategies: https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Input(batch_size, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        # Input(batch_size, 6, 24, 24)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Input(batch_size, 16, 12, 12)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        # Input(batch_size, 16, 8, 8)\n",
    "        x = self.pool()\n",
    "        \n",
    "        # Input(batch_size, 16, 4, 4)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an object of the neural network\n",
    "# Optimizer\n",
    "# Define a Loss Function\n",
    "# Run the training loop\n",
    "\n",
    "neural_net = ConvNet()\n",
    "optimizer = torch.optim.SGD(params=neural_net.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop:\n",
    "for epoch in range(10):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader, 1):\n",
    "        \n",
    "        # set optimizer gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        predictions = neural_net.forward(x)\n",
    "        \n",
    "        # backward pass + optimization step\n",
    "        loss = loss_fn(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch}, loss: {running_loss / i}')\n",
    "        \n",
    "    print(f'\\nLoss after epoch: {epoch} = {running_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = neural_net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Build your own Neural Network classifiers:\n",
    "\n",
    "### Todos:\n",
    "1. Load the CIFAR 10 train and test dataset from the torchvision library that we have used above for the MNIST data:\n",
    "Documentation: https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "2. Create DataLoaders for the training and test size:\n",
    "    - experiment with different batch sizes\n",
    "3. Create one fully connected model and another Convolutional Neural Network, for each experiment with different layer sizes(# of neurons) and layer types:\n",
    "    - Conv layers preprocess the data\n",
    "    - Pooling layers preprocess the data\n",
    "    - Fully connected layer need to be added at the end to classify the data\n",
    "\n",
    "## Note: In this solution I only used 1 fully-connected(torch.nn.Linear) layer since it accelarates the training process significantly\n",
    "\n",
    "4. Evaluate the prediction accuracy(all correct classified points / number of points) of your Fully-connected and Convolutional Neural Networks\n",
    "\n",
    "5. Evaluate prediction accuracy of each class, e.g.: Correctly classified: 60% of planes, 70% of cars, 30% of housed etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 169467904/170498071 [00:11<00:00, 16541592.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "training_data = torchvision.datasets.CIFAR10('data/', train=True, download=True, transform=transform)\n",
    "testing_data = torchvision.datasets.CIFAR10('data/', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(testing_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetCifar10(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvNetCifar10, self).__init__()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
    "        self.pool = torch.nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(16 * 5 * 5, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Input(batch_size, 1, 28, 28)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        # Input(batch_size, 6, 24, 24)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # Input(batch_size, 16, 12, 12)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        # Input(batch_size, 16, 8, 8)\n",
    "        x = self.pool(x)\n",
    "                \n",
    "        # Input(batch_size, 16, 4, 4)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an object of the neural network\n",
    "# Optimizer\n",
    "# Define a Loss Function\n",
    "# Run the training loop\n",
    "\n",
    "neural_net = ConvNetCifar10()\n",
    "optimizer = torch.optim.SGD(params=neural_net.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 2.008464808821678\n",
      "Epoch: 0, loss: 1.8425456362366677\n",
      "Epoch: 0, loss: 1.7432613690098127\n",
      "\n",
      "Loss after epoch: 0 = 1.7341665418815613\n",
      "Epoch: 1, loss: 1.472133158683777\n",
      "Epoch: 1, loss: 1.4439459372758865\n",
      "Epoch: 1, loss: 1.4211917668183645\n",
      "\n",
      "Loss after epoch: 1 = 1.4177743427276612\n",
      "Epoch: 2, loss: 1.3192310163378715\n",
      "Epoch: 2, loss: 1.3122816373705863\n",
      "Epoch: 2, loss: 1.301391716102759\n",
      "\n",
      "Loss after epoch: 2 = 1.297793385734558\n",
      "Epoch: 3, loss: 1.236536273777485\n",
      "Epoch: 3, loss: 1.2335844233632087\n",
      "Epoch: 3, loss: 1.231391068160534\n",
      "\n",
      "Loss after epoch: 3 = 1.2304240695762634\n",
      "Epoch: 4, loss: 1.1988790969252587\n",
      "Epoch: 4, loss: 1.1896469817608595\n",
      "Epoch: 4, loss: 1.1822293835083644\n",
      "\n",
      "Loss after epoch: 4 = 1.1800174136543273\n",
      "Epoch: 5, loss: 1.1536464096307755\n",
      "Epoch: 5, loss: 1.1492350935935973\n",
      "Epoch: 5, loss: 1.143739526460568\n",
      "\n",
      "Loss after epoch: 5 = 1.1428605481052398\n",
      "Epoch: 6, loss: 1.1082255973815918\n",
      "Epoch: 6, loss: 1.109588011711836\n",
      "Epoch: 6, loss: 1.1132366749445597\n",
      "\n",
      "Loss after epoch: 6 = 1.1124529468917848\n",
      "Epoch: 7, loss: 1.0768548887073994\n",
      "Epoch: 7, loss: 1.0807977945953609\n",
      "Epoch: 7, loss: 1.086460542033116\n",
      "\n",
      "Loss after epoch: 7 = 1.0872411665439605\n",
      "Epoch: 8, loss: 1.0532898060977458\n",
      "Epoch: 8, loss: 1.0637283088713885\n",
      "Epoch: 8, loss: 1.0649918649991352\n",
      "\n",
      "Loss after epoch: 8 = 1.0648410530281067\n",
      "Epoch: 9, loss: 1.0413699473142624\n",
      "Epoch: 9, loss: 1.0458770063966514\n",
      "Epoch: 9, loss: 1.0484886750082174\n",
      "\n",
      "Loss after epoch: 9 = 1.0482750215435028\n"
     ]
    }
   ],
   "source": [
    "# training loop:\n",
    "for epoch in range(10):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (x, y) in enumerate(train_loader, 1):\n",
    "        \n",
    "        # set optimizer gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        predictions = neural_net.forward(x)\n",
    "        \n",
    "        # backward pass + optimization step\n",
    "        loss = loss_fn(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch}, loss: {running_loss / i}')\n",
    "        \n",
    "    print(f'\\nLoss after epoch: {epoch} = {running_loss / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 62 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for (x, y) in test_loader:\n",
    "        \n",
    "        predictions = neural_net(x)\n",
    "        \n",
    "        _, predicted = torch.max(predictions.data, 1)\n",
    "        \n",
    "        total += y.size(0)\n",
    "        \n",
    "        correct += (predicted == y).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 56 %\n",
      "Accuracy of   car : 72 %\n",
      "Accuracy of  bird : 46 %\n",
      "Accuracy of   cat : 36 %\n",
      "Accuracy of  deer : 54 %\n",
      "Accuracy of   dog : 58 %\n",
      "Accuracy of  frog : 78 %\n",
      "Accuracy of horse : 72 %\n",
      "Accuracy of  ship : 81 %\n",
      "Accuracy of truck : 71 %\n"
     ]
    }
   ],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for (x, y) in test_loader:\n",
    "        \n",
    "        predictions = neural_net(x)\n",
    "        \n",
    "        _, predicted = torch.max(predictions, 1)\n",
    "        \n",
    "        c = (predicted == y).squeeze()\n",
    "        \n",
    "        for i in range(4):\n",
    "            label = y[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
